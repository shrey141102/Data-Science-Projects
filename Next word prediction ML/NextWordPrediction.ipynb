{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NextWordPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "7GzJi1a_0oAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zNhKqaG60lLo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data"
      ],
      "metadata": {
        "id": "PvdGs0Ws0tzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '1661-0.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length:', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw76nToF0yKr",
        "outputId": "6ad8f5dd-2086-48f8-8ba8-2088974a50db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 581888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2XdyN0vkA9pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "ez3MAuULA8Jd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eonUXq8DA-Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ],
      "metadata": {
        "id": "tyVpAlz3A-fc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "uKH4zoKIBCbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_LENGTH = 5\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print(prev_words[0])\n",
        "print(next_words[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFNLCeY_BGo1",
        "outputId": "092ab7b9-48cc-45bc-dee7-bbf182b0c4c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['project', 'gutenberg', 's', 'the', 'adventures']\n",
            "of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One hot encoding"
      ],
      "metadata": {
        "id": "1kr01RjiIbWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "dO7S8Ba7JY04"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpQ_ckiRJbMF",
        "outputId": "4c03eabf-6e8c-43ac-b54e-7a10c9fb27b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False ... False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the Model"
      ],
      "metadata": {
        "id": "U46O2R7UJiIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "ZLxeG_uXJj9R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training data"
      ],
      "metadata": {
        "id": "GYsul6niJlzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=10, shuffle=True).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__E-2U4tJnRn",
        "outputId": "18a2d9dd-f5e2-4e48-8324-d805596fa8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "811/811 [==============================] - 263s 322ms/step - loss: 6.0103 - accuracy: 0.1067 - val_loss: 7.0471 - val_accuracy: 0.1014\n",
            "Epoch 2/10\n",
            "811/811 [==============================] - 248s 306ms/step - loss: 5.7653 - accuracy: 0.1476 - val_loss: 7.9336 - val_accuracy: 0.1077\n",
            "Epoch 3/10\n",
            "811/811 [==============================] - 248s 306ms/step - loss: 5.7562 - accuracy: 0.1765 - val_loss: 8.1242 - val_accuracy: 0.1034\n",
            "Epoch 4/10\n",
            "811/811 [==============================] - 247s 305ms/step - loss: 5.4525 - accuracy: 0.2096 - val_loss: 8.0976 - val_accuracy: 0.1047\n",
            "Epoch 5/10\n",
            "137/811 [====>.........................] - ETA: 3:19 - loss: 4.8730 - accuracy: 0.2617"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the model and reloading"
      ],
      "metadata": {
        "id": "HuUc7ihzJqzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "model = load_model('keras_next_word_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "f0J9hMWPJtQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "mfaC4Dq_Juds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "1nQP9eb6JwLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "metadata": {
        "id": "VsniVFn2JxKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "metadata": {
        "id": "jXlj3QvmJy5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction"
      ],
      "metadata": {
        "id": "5Mtvs7pvJ0jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)\n",
        "        x[0, t, unique_word_index[word]] = 1\n",
        "    return x\n",
        "prepare_input(\"It is not a lack\".lower())"
      ],
      "metadata": {
        "id": "Jz8RmF_QJ1ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "metadata": {
        "id": "arT9xDWcJ274"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ],
      "metadata": {
        "id": "hpSd7MngJ4be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q =  \"There is nothing more deceptive than an obvious fact\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "metadata": {
        "id": "xCVE54TnJ51T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}